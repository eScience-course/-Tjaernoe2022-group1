{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a482c2fa-eb0e-4bbe-b8a0-223a388bf6a7",
   "metadata": {},
   "source": [
    "# eScience Course Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cab228-0463-414c-95a3-7b54842e196f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Group 1: Arctic - SCHMARTIC: SCHool of Model evaluation of AeRosol-Cloud inTeractions Important for Climate\n",
    "\n",
    "### Stefan Pfaller\n",
    "### stefan.pfaller@gmail.com\n",
    "### eScience Course 2022, Tjärnö\n",
    "### 22 November, 2022\n",
    "### Assistant: Sara Blichner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e0941-ce83-43a9-9e30-4d3e4ab97030",
   "metadata": {},
   "source": [
    "## 0. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7af9fda-2fa6-49e2-8bc2-4a50c3b28aee",
   "metadata": {},
   "source": [
    "The processes leading up to the formation of clouds is quite complex, with many cascading effects. This calls into question the accuracy of models that incorporate aerosol species that for the basis of these processes. This is done by comparing NorESM values to measured observations at the Zeppelin station in Ny-Ålesund. Sulphate and sea salt's role as aerosol sources are overestimated but do not lead to enough particles being present. This is due to the daily average concentrations of each species not being high enough, particularly in high concentration days. A decrease in particles present would change the characteristics of clouds in the model changing the overall radiative balance for the Arctic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1953a-e739-41b4-a937-83c490b46570",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "(* Indicate where I will be adding sources, having issues importing them.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45145512-6080-4fe9-8cf2-40f86e817229",
   "metadata": {},
   "source": [
    "Predicting Earth's changing climate is a vital need that requires models providing accurate and trustworthy expectations of future conditions, so that actions may be taken to avoid adverse scenarios * . This is most true in the Artic where temperatures have been increasing at up to three times the average global rates encouraged by positive feedbacks * . Many of these are positive and leading to increased warming, for example increased temperatures leading to lower sea ice cover, causing lower average surface albedo, in turn leading to further warming via decreased reflected solar radiation * . Some are negative feedbacks and could help the climate remain in a more \"normal\" state by slowing the ongoing warming. One such feedback is the indirect impact of aerosols due to low-level clouds' cooling effect as they reflect and scatter more light before it can reach Earth's surface * . Modelling these clouds correctly is very important in painting a clearer picture for the future of a rapidly changing Arctic.\n",
    "\n",
    "Modeling clouds is not as simple as just calculating the presence and height of clouds. The properties of clouds such as the brightness, cloud droplet size, and water vs ice crystal characteristics are integral in them being either net warming or net cooling * . Even when using the same sets of models, cloud feedbacks can be drastically different depending on the conditions portraied. This was show when Pithan and Mauritsen * found arctic clouds to have a slight positive feedback whilst Zelinka et al. * showed Arctic clouds to have a negative feedback despite using the same set of models. An element that influences these cloud properties is the number and composition of particles forming the cloud as well as their make up * . Cloud Condensation Nuclei (CCN) being precursors to cloud droplets (by having the potential to become activated cloud droplets), are therefore essential to properly modelling cloud properties.\n",
    "\n",
    "The number of aerosol particles above the size of 50 and 100 nanometers (N50 and N100 respectively), can be used as an accurate proxy of CCN concentrations * . This is because the larger particles will become activated first as they require a lower super saturation to start growing. CCN additionally vary largely based on their source and their composition. In the Arctic, where the number of aerosols present can be limiting * , the creation of aerosols is highly linked to the formation and properties of clouds. Sulphate is important in lining insoluble aerosols in order to make them soluble * aiding in new particle formation and aerosol size growth * . Sea Spray is another significant source of aerosol particles in the arctic. As their size is quite large, *in the accumulation mode*, they are important for developing clouds. \n",
    "\n",
    "Models have become complex enough to simulate fine aspects of Earth's atmosphere such as the source and size of aerosols, as well as atmospheric processes which lead to cloud formation. However, due to the complex nature of these interactions, it is necessary to evaluate how accurately models portrait the concentrations of these aerosol species that form the base of the cloud formation process. This investigation aims to access the accuracy of the Norwegian Earth System Model (NorESM) by comparing its results to observation data, using the Zeppelin weather station in Ny-Ålesund as the study site. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a622584-e98a-4ef3-ae0f-30546d226275",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7ec22-9489-421f-a7f8-2c2dbe75380b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1adbc-037b-4d1e-bc54-e8b0302ccdc5",
   "metadata": {},
   "source": [
    "#### 2.1 Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682695a-5517-41c4-9c21-dc45e6640d8e",
   "metadata": {},
   "source": [
    "Packages used for importing, processing and ploting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9976dd-00b5-4751-99f1-d4787a92a2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting threddsclient\n",
      "  Using cached threddsclient-0.4.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /srv/conda/envs/notebook/lib/python3.9/site-packages (from threddsclient) (2.28.1)\n",
      "Requirement already satisfied: lxml in /srv/conda/envs/notebook/lib/python3.9/site-packages (from threddsclient) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from threddsclient) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from beautifulsoup4->threddsclient) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->threddsclient) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->threddsclient) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->threddsclient) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.9/site-packages (from requests->threddsclient) (1.26.11)\n",
      "Installing collected packages: threddsclient\n",
      "Successfully installed threddsclient-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install threddsclient\n",
    "import threddsclient\n",
    "import s3fs\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05daf02-d45e-4c1f-8327-a40f8fd953c0",
   "metadata": {},
   "source": [
    "Ignoring warning to clean up the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf386991-3005-4bac-9334-807e1f069093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b28eec-5208-4595-bd35-ca0396db30cd",
   "metadata": {},
   "source": [
    "#### 2.2 Importing the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adcac6f-daac-4fbb-87ca-4e4873e5a332",
   "metadata": {},
   "source": [
    "Model data used in this investigation was sourced from two nudged NorESM runs. The first was from 2012-2015, which used observation data. The second run from 2015 until 2018 was a look into the future. The model generated N50, N100, Black carbon (BC) data as well as several types of Sulphate and Sea Salt (SS) species, which were combined into a total sulphate concentration for the sake of this investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2c6714-6da9-4032-a64e-c912f09634da",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(key=\"K1CQ7M1DMTLUFK182APD\", \n",
    "                       secret=\"3JuZAQm5I03jtpijCpHOdkAsJDNLNfZxBpM15Pi0\", \n",
    "                       client_kwargs=dict(endpoint_url=\"https://rgw.met.no\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09a5b6-1202-4fdf-9191-b3e280e64a2e",
   "metadata": {},
   "source": [
    "*Editorial note:* Where possible code will be streamlines into functions in order to clear up clutter!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2b21b2-6fd7-4f86-9157-d28b71839b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating path to 2012-2015 Model run data\n",
    "path_to_data = 's3://escience2022/Sara/NorESM_nudged_data/postproc/stations/OsloAero_intBVOC_f09_f09_mg17_full/'\n",
    "postfix = '_OsloAero_intBVOC_f09_f09_mg17_full_2012-01-01_2015-01-01_hour_locations.nc'\n",
    "\n",
    "#Selecting the variables \n",
    "varl = ['N100','N200','N50', 'BC_AI', 'SS_A1','SS_A2','SS_A3','SO4_NA', 'SO4_A1', 'SO4_A2', 'SO4_AC','SO4_PR']\n",
    "\n",
    "#Dataset for 2012 data\n",
    "def make_file_path_for_var(v,):\n",
    "    return path_to_data+v+postfix\n",
    "filelist = [make_file_path_for_var(v) for v in varl]\n",
    "list_of_s3_obj = [s3.open(s) for s in filelist]\n",
    "ds2012 = xr.open_mfdataset(list_of_s3_obj)\n",
    "\n",
    "#Creating path to 2015-2018 Model run data\n",
    "path_to_data = 's3://escience2022/Sara/NorESM_nudged_data/postproc/stations/OsloAero_intBVOC_f09_f09_mg17_ssp245/'\n",
    "postfix = '_OsloAero_intBVOC_f09_f09_mg17_ssp245_2015-01-01_2018-01-01_hour_locations.nc'\n",
    "\n",
    "#Dataset for 2015 data\n",
    "filelist = [make_file_path_for_var(v) for v in varl]\n",
    "list_of_s3_obj = [s3.open(s) for s in filelist]\n",
    "ds = xr.open_mfdataset(list_of_s3_obj)\n",
    "\n",
    "#Removing overlap and Merging the datasets\n",
    "ds2012= ds2012.sel(time= slice('2012-01-01','2014-12-31'))\n",
    "ds = xr.merge([ds2012,ds])\n",
    "\n",
    "#Creating a sum of all Sea Salt (SS_Model) and all Sulphate (SO4_Model)\n",
    "ds['SS_Model'] = 0\n",
    "ds['SS_Model'] = ds['SS_Model'] + ds['SS_A1'] + ds['SS_A2'] + ds['SS_A3']\n",
    "ds['SS_Model'].attrs['units'] ='kg/kg'\n",
    "\n",
    "ds['SO4_Model'] = 0\n",
    "ds['SO4_Model'] = ds['SO4_Model'] + ds['SO4_NA'] + ds['SO4_A1'] + ds['SO4_A2'] +  ds['SO4_AC'] + ds['SO4_PR']\n",
    "ds['SO4_Model'].attrs['units'] ='kg/kg'\n",
    "\n",
    "#Converting the concentrations from kg/kg to ug/m3 (this is how the data is represented in the observations)\n",
    "T_standard =  273.15 #K\n",
    "p_standard = 1e5 #Pa\n",
    "R = 287.058\n",
    "\n",
    "rho = p_standard/(R*T_standard)\n",
    "\n",
    "var = 'SO4_Model'\n",
    "if ds[var].attrs['units'] =='kg/kg':\n",
    "    ds[var] = ds[var]*rho\n",
    "    ds[var].attrs['units'] = 'kg/m3'\n",
    "    ## Change to ug/m3\n",
    "    ds[var] = ds[var]*1e9\n",
    "    ds[var].attrs['units'] = 'ug/m3'\n",
    "\n",
    "var = 'SS_Model'\n",
    "if ds[var].attrs['units'] =='kg/kg':\n",
    "    ds[var] = ds[var]*rho\n",
    "    ds[var].attrs['units'] = 'kg/m3'\n",
    "    ## Change to ug/m3\n",
    "    ds[var] = ds[var]*1e9\n",
    "    ds[var].attrs['units'] = 'ug/m3'\n",
    "\n",
    "#Obtaining daily values to reduce outliers\n",
    "ds_daily = ds.resample(time='d').mean('time')\n",
    "ds_daily['season']= ds_daily['time.season']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25e6a85-9dcc-41e5-9fc9-219a5e78610d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae60050-86c6-435b-b20c-76aa1f02085a",
   "metadata": {},
   "source": [
    "Observation data from Zeppelin was obtained from the open source EBAS Catalogue. Multiple timeseries were combined to overlap with the modeling data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec3f5ad2-174e-4605-a48f-56c136923457",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_opendap_urls = threddsclient.opendap_urls(\n",
    "'https://thredds.nilu.no/thredds/catalog/ebas/catalog.xml')\n",
    "\n",
    "# Importing the data\n",
    "opendap_urls = 'https://thredds.nilu.no/thredds/dodsC/ebas/NO0042G.19930101070000.20210421112338.filter_3pack..aerosol.18y.1d.NO01L_f3p_d_0042.NO01L_IC.lev2.nc'\n",
    "dsmf_SUL = xr.open_dataset(opendap_urls)\n",
    "opendap_urls = 'https://thredds.nilu.no/thredds/dodsC/ebas/NO0042G.20110101070000.20210420142507.filter_3pack...1y.1d.NO01L_f3p_d_0042.NO01L_IC.lev2.nc'\n",
    "dsmf_S2011 = xr.open_dataset(opendap_urls)\n",
    "opendap_urls = 'https://thredds.nilu.no/thredds/dodsC/ebas/NO0042G.20120101070000.20210421112338.filter_3pack...6y.1d.NO01L_f3p_d_0042.NO01L_IC.lev2.nc'\n",
    "dsmf_S2012 = xr.open_dataset(opendap_urls)\n",
    "opendap_urls = 'https://thredds.nilu.no/thredds/dodsC/ebas/NO0042G.20180101070000.20220405123416.filter_3pack...4y.1d.NO01L_f3p_d_0042.NO01L_IC.lev2.nc'\n",
    "dsmf_S2018 = xr.open_dataset(opendap_urls)\n",
    "\n",
    "#Singling out Sulphate and Sea Salt from data\n",
    "dsmf_Sul = xr.Dataset()\n",
    "dsmf_fixtime= xr.Dataset()\n",
    "dsmf_fixtime_Salt = xr.Dataset()\n",
    "dsmf_salt = xr.Dataset()\n",
    "dsmf_fixtime['SO4'] = xr.concat([dsmf_SUL['sulphate_total_ug_per_m3'],dsmf_S2011['sulphate_total_ug_per_m3'],dsmf_S2012['sulphate_total_ug_per_m3'],dsmf_S2018['sulphate_total_ug_per_m3']],dim = 'time')\n",
    "dsmf_fixtime_Salt['SS'] = xr.concat([dsmf_SUL['sodium'],dsmf_S2011['sodium'],dsmf_S2012['sodium'],dsmf_S2018['sodium']],dim = 'time')\n",
    "\n",
    "#Values were samples at 19:00, resampling at 00:00 resolves any conflict when plotting\n",
    "dsmf_Sul = dsmf_fixtime.resample(time='d').mean('time')\n",
    "dsmf_salt = dsmf_fixtime_Salt.resample(time='d').mean('time')\n",
    "\n",
    "\n",
    "# get all data urls for one station, e.g., Zeppelin NO0042G\n",
    "opendap_urls = [x for x in all_opendap_urls if 'NO0042G' in x]\n",
    "# get all scattering data urls\n",
    "opendap_urls = [x for x in opendap_urls if 'particle_number_size_distribution' in x]\n",
    "opendap_urls = [x for x in opendap_urls if 'lev2' in x]\n",
    "\n",
    "dsmf00 = xr.open_mfdataset(opendap_urls[3:4])\n",
    "dsmf06 = xr.open_mfdataset(opendap_urls[2:3])\n",
    "dsmf08 = xr.open_mfdataset(opendap_urls[:1])\n",
    "dsmf10 = xr.open_dataset('../../../Data/dNdlogD_data_dmps_cleaned_2010-2020.nc')\n",
    "\n",
    "#Values are hourly, resampling in order to get daily values\n",
    "daily2000 = dsmf00.resample(time='d').mean('time')\n",
    "daily2006 = dsmf06.resample(time='d').mean('time')\n",
    "daily2008 = dsmf08.resample(time='d').mean('time')\n",
    "daily2010 = dsmf10.resample(time='d').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c573eb09-4d7d-49b6-8f84-045cdd207314",
   "metadata": {},
   "source": [
    "N50 and N100 values were calculated using a numeric integration of the number particle size distribution curves for sampling time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b61bc3b-9212-42ad-aa6d-1688d03d3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sizedist_Util import compute_Nx_ebas_cleaned\n",
    "\n",
    "ds_Nx_2000 =xr.Dataset()\n",
    "ds_Nx_2000['N50'] = compute_Nx_ebas_cleaned(daily2000, x=50)\n",
    "ds_Nx_2000['N100'] = compute_Nx_ebas_cleaned(daily2000, x=100)\n",
    "\n",
    "ds_Nx_2006 =xr.Dataset()\n",
    "ds_Nx_2006['N50'] = compute_Nx_ebas_cleaned(daily2006, x=50)\n",
    "ds_Nx_2006['N100'] = compute_Nx_ebas_cleaned(daily2006, x=100)\n",
    "\n",
    "ds_Nx_2008 =xr.Dataset()\n",
    "ds_Nx_2008['N50'] = compute_Nx_ebas_cleaned(daily2008, x=50)\n",
    "ds_Nx_2008['N100'] = compute_Nx_ebas_cleaned(daily2008, x=100)\n",
    "\n",
    "ds_Nx_2010 =xr.Dataset()\n",
    "ds_Nx_2010['N50'] = compute_Nx_ebas_cleaned(daily2010, x=50, var_diam = 'diameter', v_dNdlog10D='dNdlogD')\n",
    "ds_Nx_2010['N100'] = compute_Nx_ebas_cleaned(daily2010, x=100, var_diam = 'diameter', v_dNdlog10D='dNdlogD')\n",
    "\n",
    "#There is one day of overlap between the 2008 and 2010 data so this was removed before concatenating.\n",
    "ds_Nx_2011 = ds_Nx_2010.sel(time=slice('2011-01','2020-12'))\n",
    "ds_Nx_all = xr.concat([ds_Nx_2000, ds_Nx_2006, ds_Nx_2008, ds_Nx_2011], dim = 'time',coords='minimal',compat='override')\n",
    "\n",
    "ds = xr.merge([dsmf_Sul.sel(time=slice('2000-03','2020-12')),ds_Nx_all,dsmf_salt.sel(time=slice('2000-03','2020-12'))])\n",
    "ds['SO4'].attrs['Units'] = 'ug/m$^3$'\n",
    "ds['N50'].attrs['Units'] = 'N50'\n",
    "ds['N100'].attrs['Units'] = 'N100'\n",
    "ds['SS'].attrs['Units'] = 'ug/m$^3$'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44eaae-c7a4-4171-a4c5-1a1543bf0ba3",
   "metadata": {},
   "source": [
    "In order to make realistic comparisons with the observation data, the bottom layer of the NorESM model in Zeppelin was extracted from the rest of the data. Thi was done since NorESM is uses a hybrid pressure layer model so the bottom layer follows the surface topography to some extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6b0c77-f09a-42c6-afee-32aece0623f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only Zeppelin station and data from the bottom pressure layer\n",
    "Model_ds = ds_daily.sel(location='Zeppelin').isel(lev = -1)\n",
    "\n",
    "#Renaming variables to avoid conflicts\n",
    "Model_ds['N50_Model'] = Model_ds['N50']\n",
    "Model_ds['N100_Model'] = Model_ds['N100']\n",
    "Model_ds = Model_ds.drop_vars(['N50','N100'])\n",
    "\n",
    "#Combining the observation and Model data\n",
    "ALLDATA = xr.merge([ds,Model_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcb336-e9c2-4143-9274-42f0ef67abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLDATA = ALLDATA.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0114d1e-ab37-4d1f-a4e9-9883e2dadb01",
   "metadata": {},
   "source": [
    "Defining seasons and months, in order to group by these categories and establish any potential temporal trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e300ea-c70b-4214-8299-5ab998e4b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLDATA['Season'] = ALLDATA['time.season']\n",
    "ALLDATA['Month'] = ALLDATA['time.month']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e1cf17-65dd-4b3d-be88-ebae98f7b08a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0653e-fb64-4f0d-983d-f359699f4989",
   "metadata": {},
   "source": [
    "## 3. Results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0496f30-e60b-41b3-8fef-c5bf9a7be00f",
   "metadata": {},
   "source": [
    "### 3.1 Particle formation processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580461f4-f830-48cf-95e9-9322d6552149",
   "metadata": {},
   "source": [
    "In order to determine the influence of sulphate on particle formation, daily values of SO4 was plotted against N50 (Figure 1). This was done for observation data as well as NorESM data, with the observation data in blue, whilst the NorESM data is in yellow. The model shows a stronger correlation between the two variables than the observations. A linear regression was done for the , the resulting lines had slopes of 293.8 and 122.5 for the NorESM and observation data respectively. This suggests that in the arctic, the model estimates the influence of SO4 on small particles formation to be greater than it is in treal life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2fa24-80cc-4819-b9d2-c8c93d23a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2,tight_layout=True, sharey=True, sharex=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "_dss = ALLDATA[['SO4_Model','N50_Model']].dropna('time')\n",
    "ax1.scatter(x=_dss['SO4_Model'], y=_dss['N50_Model'],c='orange',alpha = 0.2)\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4_Model'], _dss['N50_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['SO4_Model'].min()), np.log10(_dss['SO4_Model'].max()))\n",
    "#print(p)\n",
    "ax1.plot( x, p(x), c = 'black', )\n",
    "ax1.text(0.083, 0.12, 'Linear regression : y = 293.8 x + 34.36' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4_Model']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50_Model'])\n",
    "r_sq = model.score(x, _dss['N50_Model'])\n",
    "#print(f\"coefficient of determination: {r_sq}\")\n",
    "ax1.text(0.9, 0.18, f'R$^2$ value : {r_sq:0.3f}' ,fontsize=8)\n",
    "\n",
    "ax1.set_ylim(0.1,10000)\n",
    "ax1.set_xlim(0.002,5)\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "#ax1.set_xlabel('SO4 ug/m$^3$')\n",
    "#ax1.set_ylabel('N50')\n",
    "ax1.set_title(f'Model')\n",
    "\n",
    "_dss = ALLDATA[['SO4','N50']].dropna('time')\n",
    "ax2.scatter(x=_dss['SO4'], y=_dss['N50'], alpha = 0.2 )\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4'], _dss['N50'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-1.2, np.log10(_dss['SO4'].max()))\n",
    "#print(p)\n",
    "ax2.plot( x, p(x), c = 'black', )\n",
    "ax2.text(0.09, 0.12, 'Linear regression : y = 122.5x + 74.98' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50'])\n",
    "r_sq = model.score(x, _dss['N50'])\n",
    "#print(r_sq)\n",
    "ax2.text(1.05, 0.18, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_ylim(0.1,10000)\n",
    "ax2.set_xlim(0.002,5)\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "#plt.xlabel('SO4 ug/m$^3$')\n",
    "#plt.ylabel('N50 ')\n",
    "ax2.set_title(f'Observation')\n",
    "#f.suptitle('Influence of SO4 on N$_{50}$ at Zeppelin', fontsize=16)\n",
    "f.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "f.supylabel('N$_{50}$ (cm$^{-3}$)')\n",
    "\n",
    "f.text(0, -0.05,\n",
    "         'Figure 1: NorESM (yellow) vs obesrvation (blue) SO4 vs N$_{50}$ at Zeppelin Station in Ny-Ålesund. Black lines represent linear regressions plotted in log space.')\n",
    "\n",
    "sns.despine(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30daddae-99b3-4dd8-ab71-3aadb42b1061",
   "metadata": {},
   "source": [
    "Figure 2 shows the same relationship as figure 1 for SO4 now plotted against N100. In this figure, the slopes of both linear regressions appear to be very similar. Both when comparing sulphate to N50 as well as N100, the R-squared values of the Model data is far better than the observation data meaning a better fit between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f6992-4c30-4153-a492-7758fd7d6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2,tight_layout=True, sharey=True, sharex=True, figsize = (10,5))\n",
    "\n",
    "_dss = ALLDATA[['SO4_Model','N100_Model']].dropna('time')\n",
    "ax1.scatter(x=_dss['SO4_Model'], y=_dss['N100_Model'],c='orange',alpha = 0.2)\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4_Model'], _dss['N100_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['SO4_Model'].min()), np.log10(_dss['SO4_Model'].max()))\n",
    "#print(p)\n",
    "ax1.plot( x, p(x), c = 'black', )\n",
    "ax1.text(0.083, 0.12, 'Linear regression : y = 113.4 x + 10.26' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4_Model']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N100_Model'])\n",
    "r_sq = model.score(x, _dss['N100_Model'])\n",
    "#print(f\"coefficient of determination: {r_sq}\")\n",
    "ax1.text(0.9, 0.18, f'R$^2$ value : {r_sq:0.3f}' ,fontsize=8)\n",
    "\n",
    "ax1.set_ylim(0.1,10000)\n",
    "ax1.set_xlim(0.002,5)\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "#ax1.set_xlabel('SO4 ug/m$^3$')\n",
    "#ax1.set_ylabel('N100')\n",
    "ax1.set_title(f'Model')\n",
    "\n",
    "_dss = ALLDATA[['SO4','N100']].dropna('time')\n",
    "ax2.scatter(x=_dss['SO4'], y=_dss['N100'], alpha = 0.2 )\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4'], _dss['N100'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-1.2, np.log10(_dss['SO4'].max()))\n",
    "#print(p)\n",
    "ax2.plot( x, p(x), c = 'black', )\n",
    "ax2.text(0.084, 0.12, 'Linear regression : y = 109.1 x + 35.70' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N100'])\n",
    "r_sq = model.score(x, _dss['N100'])\n",
    "#print(r_sq)\n",
    "ax2.text(0.92, 0.18, f\"R$^2$-value : {r_sq:.3f}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_ylim(0.1,10000)\n",
    "ax2.set_xlim(0.002,5)\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "#plt.xlabel('SO4 ug/m$^3$')\n",
    "#plt.ylabel('N100 ')\n",
    "ax2.set_title(f'Observation')\n",
    "#f.suptitle('Influence of SO4 on N$_{100}$ at Zeppelin', fontsize=16)\n",
    "f.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "f.supylabel('N$_{100}$ (cm$^{-3}$)')\n",
    "f.text(0, -0.05,\n",
    "         'Figure 2: NorESM (yellow) vs observation (blue) SO4 vs N$_{100}$ at Zeppelin Station in Ny-Ålesund. Black lines represent linear regressions plotted in log space.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.despine(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93184460-5962-4b87-9b0a-5f65ecb24351",
   "metadata": {},
   "source": [
    "As seasalt is one of the largest sources of aerosols, it might also have an important role in the model's sources of N50 and N100 values. Figure 3 presents the relationship between the concentrations of sea salt and N50 in both the model (yellow) and observations (blue). The model shows a 6.0 times lower relationship of N50 particles to sea salt than is present in the observation data. For the observation data there are most data points clustered around median concentrations of Sea salt (0.14 ug/m3). In the model data however, the spread of the sea salt concentrations is far higher. Striation of the observation data at low concentrations is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1a9a7-8439-45a3-9d68-3d9436fe050b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2,tight_layout=True, sharey=True, sharex=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "_dss = ALLDATA[['SS_Model','N50_Model']].dropna('time')\n",
    "ax1.scatter(x=_dss['SS_Model'], y=_dss['N50_Model'],c='orange',alpha = 0.2)\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SS_Model'], _dss['N50_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['SS_Model'].min()), np.log10(_dss['SS_Model'].max()))\n",
    "#print(p)\n",
    "ax1.plot( x, p(x), c = 'black', )\n",
    "ax1.text(0.083, 0.12, 'Linear regression : y = 14.36 x + 57.16' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SS_Model']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50_Model'])\n",
    "r_sq = model.score(x, _dss['N50_Model'])\n",
    "#print(f\"coefficient of determination: {r_sq}\")\n",
    "ax1.text(0.9, 0.18, f'R$^2$ value : {r_sq:0.3f}' ,fontsize=8)\n",
    "\n",
    "ax1.set_ylim(0.1,10000)\n",
    "ax1.set_xlim(0.002,40)\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "#ax1.set_xlabel('SS ug/m$^3$')\n",
    "#ax1.set_ylabel('N50')\n",
    "ax1.set_title(f'Model')\n",
    "\n",
    "_dss = ALLDATA[['SS','N50']].dropna('time')\n",
    "ax2.scatter(x=_dss['SS'], y=_dss['N50'], alpha = 0.2 )\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SS'], _dss['N50'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-2, np.log10(_dss['SS'].max()))\n",
    "#print(p)\n",
    "ax2.plot( x, p(x), c = 'black', )\n",
    "ax2.text(0.09, 0.12, 'Linear regression : y = 85.95 x + 105.2' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SS']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50'])\n",
    "r_sq = model.score(x, _dss['N50'])\n",
    "#print(r_sq)\n",
    "ax2.text(1.05, 0.18, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_ylim(0.1,10000)\n",
    "ax2.set_xlim(0.002,40)\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "#plt.xlabel('SS ug/m$^3$')\n",
    "#plt.ylabel('N50 ')\n",
    "ax2.set_title(f'Observation')\n",
    "#f.suptitle('Influence of SS on N$_{50}$ at Zeppelin', fontsize=16)\n",
    "f.supxlabel('SS ug/m$^3$')\n",
    "f.supylabel('N$_{50}$ (cm$^{-3}$)')\n",
    "\n",
    "f.text(0, -0.05,\n",
    "         'Figure 3: NorESM (yellow) vs obesrvation (blue) Sea Salt vs N$_{50}$ at Zeppelin Station in Ny-Ålesund. Black lines represent linear regressions plotted in log space.')\n",
    "\n",
    "\n",
    "\n",
    "sns.despine(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0be5af-f53b-4c70-94d0-88011940eabb",
   "metadata": {},
   "source": [
    "Figure 4 shows sea salt concentrations against N100 concentrations in NorESM and observations. Since Sea salt concentrations are being plotted here as well as in figure 3, the same striation at low concentrations and general clustering around median concentrations (0.14 ug/m3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19294cd-37a8-49aa-b4eb-61da9929d4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2,tight_layout=True, sharey=True, sharex=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "_dss = ALLDATA[['SS_Model','N100_Model']].dropna('time')\n",
    "ax1.scatter(x=_dss['SS_Model'], y=_dss['N100_Model'],c='orange',alpha = 0.2)\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SS_Model'], _dss['N100_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['SS_Model'].min()), np.log10(_dss['SS_Model'].max()))\n",
    "#print(p)\n",
    "ax1.plot( x, p(x), c = 'black', )\n",
    "ax1.text(0.083, 0.12, 'Linear regression : y = 8.055 x + 16.01' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SS_Model']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N100_Model'])\n",
    "r_sq = model.score(x, _dss['N100_Model'])\n",
    "#print(f\"coefficient of determination: {r_sq}\")\n",
    "ax1.text(0.9, 0.18, f'R$^2$ value : {r_sq:0.3f}' ,fontsize=8)\n",
    "\n",
    "ax1.set_ylim(0.1,10000)\n",
    "ax1.set_xlim(0.002,40)\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "#ax1.set_xlabel('SS ug/m$^3$')\n",
    "#ax1.set_ylabel('N100')\n",
    "ax1.set_title(f'Model')\n",
    "\n",
    "_dss = ALLDATA[['SS','N100']].dropna('time')\n",
    "ax2.scatter(x=_dss['SS'], y=_dss['N100'], alpha = 0.2 )\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SS'], _dss['N100'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-2, np.log10(_dss['SS'].max()))\n",
    "#print(p)\n",
    "ax2.plot( x, p(x), c = 'black', )\n",
    "ax2.text(0.09, 0.12, 'Linear regression : y = 59.64 x + 66.65' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SS']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N100'])\n",
    "r_sq = model.score(x, _dss['N100'])\n",
    "#print(r_sq)\n",
    "ax2.text(1.05, 0.18, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_ylim(0.1,10000)\n",
    "ax2.set_xlim(0.002,40)\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "#plt.xlabel('SS ug/m$^3$')\n",
    "#plt.ylabel('N100 ')\n",
    "ax2.set_title(f'Observation')\n",
    "f.suptitle('Influence of SS on N$_{100}$ at Zeppelin', fontsize=16)\n",
    "f.supxlabel('SS ug/m$^3$')\n",
    "f.supylabel('N$_{100}$ (cm$^{-3}$)')\n",
    "f.text(0, -0.05,\n",
    "         'Figure 4: NorESM (yellow) vs obesrvation (blue) Sea Salt vs N$_{100}$ at Zeppelin Station in Ny-Ålesund. Black lines represent linear regressions plotted in log space.')\n",
    "\n",
    "\n",
    "sns.despine(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b760ff-b4e9-4e48-9131-22297a17cd65",
   "metadata": {},
   "source": [
    "### 3.2 Accuracy of NorESM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ddf2e7-712a-48cc-b128-e693d7f6687c",
   "metadata": {},
   "source": [
    "In order to determine how accurately NorESM models the conditions present in Zeppelin, each data variable was compared to the daily averages of the same date in the measurement data. In the sulphate, N50 and N100 concentrations, datapoints have a tendency to be below the 1:1 line. Sea salt concentrations appear to be above the 1:1 line. This same pattern is seen in the slopes of the linear regressions all falling below 1. For sea salt, most datapoints are above the 1:1 line and similarly the slope of the linear regression is above 1. It is good to note that the axes of the sulphate comparison scatterplot are have minima that are different by a magnitude of 2 orders. This is why the 1:1 line may look quite different from the other scatterplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d713c-1b19-4988-ad9c-35df59ad1d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, tight_layout= True, figsize = (10,10))\n",
    "\n",
    "ax1.scatter(x = ALLDATA['SO4'], y = ALLDATA['SO4_Model'],alpha = 0.15)\n",
    "_dss = ALLDATA.to_dataframe().dropna()\n",
    "z = np.polyfit(_dss['SO4'], _dss['SO4_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-1, np.log10(_dss['SO4'].max()))\n",
    "ax1.plot( x, p(x), c = 'blue', )\n",
    "ax1.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax1.text(1.5, 0.00095, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax1.set_xlim(0.08,5)\n",
    "ax1.set_title ('SO4')\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "\n",
    "ax2.scatter(x = ALLDATA['N50'], y = ALLDATA['N50_Model'],alpha = 0.15)\n",
    "z = np.polyfit(_dss['N50'], _dss['N50_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['N50'].min()), np.log10(_dss['N50'].max()))\n",
    "ax2.plot( x, p(x), c = 'blue', )\n",
    "ax2.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax2.text(200.0, 1.9, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_title ('N$_{50}$')\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "\n",
    "ax3.scatter(x = ALLDATA['N100'], y = ALLDATA['N100_Model'],alpha = 0.15)\n",
    "z = np.polyfit(_dss['N100'], _dss['N100_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['N100'].min()), np.log10(_dss['N100'].max()))\n",
    "ax3.plot( x, p(x), c = 'blue', )\n",
    "ax3.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax3.text(70.0, 0.6, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax3.set_title ('N$_{100}$')\n",
    "ax3.set_yscale ('log')\n",
    "ax3.set_xscale ('log')\n",
    "\n",
    "ax4.scatter(x = ALLDATA['SS'], y = ALLDATA['SS_Model'],alpha = 0.15)\n",
    "z = np.polyfit(_dss['SS'], _dss['SS_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-2, np.log10(_dss['SS'].max()))\n",
    "ax4.plot( x, p(x), c = 'blue', )\n",
    "ax4.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax4.text(0.5, 0.00015, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax4.set_title ('Sea Salt')\n",
    "ax4.set_yscale ('log')\n",
    "ax4.set_xscale ('log')\n",
    "\n",
    "f.supxlabel('Observations')\n",
    "f.supylabel('NorESM')\n",
    "#f.suptitle('NorESM data against Observation data')\n",
    "f.text(0, -0.05,\n",
    "         'Figure 5: NorESM data vs observation data at Zeppelin for respective variable concentrations. Black lines represent the 1:1 line, blue line represents the linear regression analysis.')\n",
    "\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd02bdc-99a9-4734-9cc4-f777d660b6a0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d9a93-dba2-4035-bded-6ddae7fe65de",
   "metadata": {},
   "source": [
    "## 4. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebaea6-9ff3-44ee-8892-81a1cbb8e75e",
   "metadata": {},
   "source": [
    "Sulphate is important in making particles that are soluble allowing them to grow by allowing water to grow on them. We can see that the model also acknowledges the role of sulphate in new particle formation, however, it seems to overestimate the influence of sulphate's role. This is because whilst the slope of the model data for sulphate vs N100 is similar to that in the observation data (Figure 2), when including smaller particle sizes (N50) the slope of the model data is more than 2.5 times higher than that of the observation data (Figure 1). Additionally, the fairly good r-squared values of around 0.31 for the linear regression (given the complicated nature of particle formation), suggests that sulphate is a main reason for the trend seen in the model.\n",
    "\n",
    "When analysing how the model represents sea salt, it would be expected for sea salt to have a larger influence on the N100 concentration given that sea salt particles are usually slightly larger. NorESM represents this quite accurately since the r-squared value of the linear regression increases from 0.249 to 0.515 when comparing sea salt to N50 and N100 respectively. It is curious however, that the difference between the slopes of the model and observation data increases as well when moving from N50 to N100. This means that despite the model correctly identifying sea salt's increased role in the formation of larger particles, it underestimates how many of these particles are being created. When looking at N100, this could due to NorESM producing too many large sea salt aerosols as this would result in a smaller number of particles whilst keeping the concentration of sodium (which is used as the proxy for sea salt particles) high.\n",
    "\n",
    "Directly comparing NorESM values to observation values for each variable indicated that NorESM underestimated the concentrations of all variables with the exception of sea salt. For N100, this underestimation seems only slight as many of the datapoints seem to fall close to the 1:1 line. The fact that sea salt concentrations are overestimated could balance out the fact that this concentration is not spread out across enough particles. When it comes to CCN production, this could still be problematic as it would result in the correct number of particles, however these would be too large in diameter. Concentrations of N50 seem to be underestimated in the model which opposes the overstimation of sulphates role in new particle formation. This is due to the fact that, as seen in figure 4, low concentrations of sulphate are more accurately measured, whereas higher concentrations events are not as frequent as they should be. This means that despite the model creating too many small particles when sulphate is present, the lack of sulphate is more prevalent resulting in too few small particles overall.\n",
    "\n",
    "It is important to note that a strong limitation of this investigation is the banded striation visible in most of the obesrvation data. This can be explained when plotting SO4 on its own, see supplementary figure 1. Despite the observation data being daily averages, the concentrations seem to become grouped into increments of 0.1 ug/m3 for SO4 and 0.01 ug/m3 for sea salt. This is likely a large reason for why the r-squared values are very low in the observation data as the concentrations that would be between these increments are not accurately measured, making it hard to determine the correlation and potential causality between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0501179f-0373-46c6-8325-cefce401c6cc",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c00e97-83a4-4c59-9b26-1fb07e071c2d",
   "metadata": {},
   "source": [
    "Whilst NorESM does take many intricate processes into account that lead to the formation of aerosols and eventually clouds, many of these processes are not modelled as accurately as they could when looking at the Arctic. Whilst some of these errors balance out (eg. the overestimation of sea salt concentrations paired with the underestimation of particle numbers of sea salt aerosols), the eventual influence on cloud formation processes could be important as size and solubility of CCN's are crucial. Errors in particle sizes could have a knock-on effect with incorrect numbers of CCN's being activated, thereby influencing the optical properties of the clouds and changing the radiative balance for a very sensitive region of the earth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6280d95-8d92-4116-b779-a28b20feac2b",
   "metadata": {},
   "source": [
    "## 6. Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3a0b9-adf5-45d9-9f99-4088982f5119",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "075e1764-cc68-46c4-9e08-0e10d7944341",
   "metadata": {},
   "source": [
    "## 7. Acknowledgements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd619558-6dd3-4955-9531-d5536acd3527",
   "metadata": {},
   "source": [
    "Special thanks to Sara for lots of advice and guidance regarding coding and understanding of scientific background. Thank you to Michael Schulz and Paul Zieger for organizing this course which has already greatly increased my coding abilities, thereby aiding in any future projects of mine that include data processing of large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc4fe7-02e4-4e77-846f-b842adae54b8",
   "metadata": {},
   "source": [
    "### 8. Supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ccdb6-c25f-4b9f-aad6-b29664d470d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1,tight_layout=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "#_dss = ALLDATA[['SO4_Model','N100_Model']].dropna('time')\n",
    "ax1.plot(ALLDATA['SO4'].sel(time=slice('2015-01','2017-12')))\n",
    "\n",
    "f.text(0.3, -0.05,\n",
    "         'Supplementary Figure 1: Plotting SO$_4$ observation data')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63be4a-7569-4c26-a9eb-3fd387a57a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Levels = ds_daily.sel(location = 'Zeppelin').isel(lev= [-31,-25,-19,-13,-7,-1])\n",
    "Levels = Levels.load()\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize = [10,5], sharex=True, sharey=True)\n",
    "\n",
    "#ax.set_ylim ([0,750])\n",
    "#ax.set_xlim ([0,1.2])\n",
    "\n",
    "for lev, ax in zip(Levels['lev'], axs.flatten()):\n",
    "    #print(lev)\n",
    "    _dss = Levels.where(Levels['lev']==lev)\n",
    "    _dss = _dss.to_dataframe().dropna()\n",
    "    ax.scatter(x=_dss['SO4_Model'], y=_dss['N100'], alpha = 0.2 )\n",
    "    z = np.polyfit(_dss['SO4_Model'], _dss['N100'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x= np.logspace(np.log10(_dss['SO4_Model'].min()), np.log10(_dss['SO4_Model'].max()))\n",
    "    ax.plot( x, p(x), c = 'black', )\n",
    "    #print(p)\n",
    "    #ax.set_ylim ([7,100])\n",
    "    #ax.set_xlim ([0.007,0.2])\n",
    "    ax.set_ylim ([0.001,700])\n",
    "    ax.set_xlim ([0.0001,4])\n",
    "    \n",
    "    ax.set_yscale ('log')\n",
    "    ax.set_xscale ('log')\n",
    "    ax.set_title(f'{lev.values:.1f} hPa')\n",
    "    \n",
    "    #Calculating R-Squared\n",
    "    x = np.array([_dss['SO4_Model']]).reshape((-1, 1))\n",
    "    model = LinearRegression().fit (x, _dss['N100'])\n",
    "    r_sq = model.score(x, _dss['N100'])\n",
    "    ax.text(0.08, 2, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "    #ax.text(0.3, 0.15, f\"R$^2$-value:{r_sq}0.3f\"  ,fontsize=8)\n",
    "\n",
    "    \n",
    "fig.supxlabel('SO4 ug/m$^3$')\n",
    "fig.supylabel('N$_{100}$ ug/cm$^3$')\n",
    "\n",
    "fig.text(0.2, -0.05,\n",
    "         'Supplementary Figure 2: SO$_4$ against N100 at different elevations from the NorESM model')\n",
    "\n",
    "sns.despine(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4974ff23-bb51-4874-81bf-9f7c3501759b",
   "metadata": {},
   "source": [
    "## Removing bottom 14%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71943be8-9d5f-4200-83cb-aa98414495b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked = ALLDATA.where(ALLDATA['SO4']>0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0a9f7-6c9f-40ac-8077-e3ab786e539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax1 = plt.subplots()\n",
    "\n",
    "ax1.scatter(x = masked['SO4'], y = masked['SO4_Model'],alpha = 0.15)\n",
    "_dss = masked.to_dataframe().dropna()\n",
    "z = np.polyfit(_dss['SO4'], _dss['SO4_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-1, np.log10(_dss['SO4'].max()))\n",
    "ax1.plot( x, p(x), c = 'blue', )\n",
    "ax1.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax1.text(1.5, 0.00095, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax1.set_xlim(0.08,5)\n",
    "ax1.set_title ('SO4')\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a805126-413a-4799-8e37-384eaae54211",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2,tight_layout=True, sharey=True, sharex=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "_dss = ALLDATA[['SO4_Model','N50_Model']].dropna('time')\n",
    "ax1.scatter(x=_dss['SO4_Model'], y=_dss['N50_Model'],c='orange',alpha = 0.2)\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4_Model'], _dss['N50_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['SO4_Model'].min()), np.log10(_dss['SO4_Model'].max()))\n",
    "#print(p)\n",
    "ax1.plot( x, p(x), c = 'black', )\n",
    "ax1.text(0.083, 0.12, 'Linear regression : y = 293.8 x + 34.36' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4_Model']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50_Model'])\n",
    "r_sq = model.score(x, _dss['N50_Model'])\n",
    "#print(f\"coefficient of determination: {r_sq}\")\n",
    "ax1.text(0.9, 0.18, f'R$^2$ value : {r_sq:0.3f}' ,fontsize=8)\n",
    "\n",
    "ax1.set_ylim(0.1,10000)\n",
    "ax1.set_xlim(0.002,5)\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "#ax1.set_xlabel('SO4 ug/m$^3$')\n",
    "#ax1.set_ylabel('N50')\n",
    "ax1.set_title(f'Model')\n",
    "\n",
    "_dss = ALLDATA[['SO4','N50']].dropna('time')\n",
    "ax2.scatter(x=_dss['SO4'].sel(time=slice('2020-01','2022-12')), y=_dss['N50'].sel(time=slice('2020-01','2022-12')), alpha = 0.2 )\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4'].sel(time=slice('2020-01','2022-12')), _dss['N50'].sel(time=slice('2020-01','2022-12')), 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-1.2, np.log10(_dss['SO4'].sel(time=slice('2020-01','2022-12')).max()))\n",
    "#print(p)\n",
    "ax2.plot( x, p(x), c = 'black', )\n",
    "#ax2.text(0.09, 0.12, 'Linear regression : y = 122.5x + 74.98' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4'].sel(time=slice('2020-01','2022-12'))]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50'].sel(time=slice('2020-01','2022-12')))\n",
    "r_sq = model.score(x, _dss['N50'].sel(time=slice('2020-01','2022-12')))\n",
    "#print(r_sq)\n",
    "ax2.text(1.05, 0.18, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_ylim(0.1,10000)\n",
    "ax2.set_xlim(0.002,5)\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "#plt.xlabel('SO4 ug/m$^3$')\n",
    "#plt.ylabel('N50 ')\n",
    "ax2.set_title(f'Observation')\n",
    "#f.suptitle('Influence of SO4 on N$_{50}$ at Zeppelin', fontsize=16)\n",
    "f.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "f.supylabel('N$_{50}$ (cm$^{-3}$)')\n",
    "\n",
    "f.text(0, -0.05,\n",
    "         'Figure 1: NorESM (yellow) vs obesrvation (blue) SO4 vs N$_{50}$ at Zeppelin Station in Ny-Ålesund. Black lines represent linear regressions plotted in log space.')\n",
    "\n",
    "sns.despine(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb11bb-0083-440a-94d0-179d5a09fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1,tight_layout=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "#_dss = ALLDATA[['SO4_Model','N100_Model']].dropna('time')\n",
    "ax1.scatter(x= ALLDATA['time'].sel(time=slice('2010-01','2022-12')), y = ALLDATA['SO4'].sel(time=slice('2010-01','2022-12')))\n",
    "ax1.set_ylim(-0.2,3.5)\n",
    "\n",
    "f.text(0.3, -0.05,\n",
    "         'Supplementary Figure 1: Plotting SO$_4$ observation data')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b14ca-e64c-4725-ae04-473a4198d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1,tight_layout=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "#_dss = ALLDATA[['SO4_Model','N100_Model']].dropna('time')\n",
    "ax1.scatter(x= ALLDATA['time'].sel(time=slice('2017-01','2022-12')), y = ALLDATA['SS'].sel(time=slice('2017-01','2022-12')))\n",
    "ax1.set_ylim(-0.02,.5)\n",
    "\n",
    "f.text(0.3, -0.05,\n",
    "         'Supplementary Figure 1: Plotting SS observation data')\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f14f7-c6f6-4f9f-b39c-c12f7f9e2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "#ax.set_ylim ([0,750])\n",
    "#ax.set_xlim ([0,1.2])\n",
    "\n",
    "\n",
    "\n",
    "for seas, ax, col in zip(['DJF','MAM','JJA','SON'], axs.flatten(),['blue','green','orange','red']):\n",
    "    #print(seas)\n",
    "    _dss = masked.where(masked['season']==seas)\n",
    "    _dss = _dss.to_dataframe().dropna()\n",
    "    ax.scatter(x=_dss['SO4'], y=_dss['N100'],c= col, alpha = 0.2)\n",
    "    z = np.polyfit(_dss['SO4'], _dss['N100'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x= np.logspace(-0.7, np.log10(_dss['SO4'].max()))\n",
    "    ax.plot( x, p(x), c = col, )\n",
    "    #print(p)\n",
    "    #ax.set_ylim ([0,300])\n",
    "    #ax.set_xlim ([0,2])\n",
    "    ax.set_yscale ('log')\n",
    "    ax.set_xscale ('log')\n",
    "    ax.set_title(seas)\n",
    "    \n",
    "    #Calculating R-Squared\n",
    "    x = np.array([_dss['SO4']]).reshape((-1, 1))\n",
    "    model = LinearRegression().fit (x, _dss['N100'])\n",
    "    r_sq = model.score(x, _dss['N100'])\n",
    "    ax.text(1, 1.18, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "    #ax.text(0.3, 0.15, f\"R$^2$-value:{r_sq}0.3f\"  ,fontsize=8)\n",
    "    \n",
    "fig.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "fig.supylabel('N$_{100}$ (cm$^{-3}$)')\n",
    "fig.suptitle('Obs SO4 vs N100')\n",
    "    \n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d813a6e-10b0-4770-9e7d-a508a2766b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "#ax.set_ylim ([0,750])\n",
    "#ax.set_xlim ([0,1.2])\n",
    "\n",
    "\n",
    "\n",
    "for seas, ax, col in zip(['DJF','MAM','JJA','SON'], axs.flatten(),['blue','green','orange','red']):\n",
    "    #print(seas)\n",
    "    _dss = masked.where(masked['season']==seas)\n",
    "    _dss = _dss.to_dataframe().dropna()\n",
    "    ax.scatter(x=_dss['SO4_Model'], y=_dss['N100_Model'],c= col, alpha = 0.2)\n",
    "    z = np.polyfit(_dss['SO4_Model'], _dss['N100_Model'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x= np.logspace(-2.2, np.log10(_dss['SO4_Model'].max()))\n",
    "    ax.plot( x, p(x), c = col, )\n",
    "    print(p)\n",
    "    #ax.set_ylim ([0,150])\n",
    "    #ax.set_xlim ([0,1])\n",
    "    ax.set_yscale ('log')\n",
    "    ax.set_xscale ('log')\n",
    "    ax.set_title(seas)\n",
    "    \n",
    "    #Calculating R-Squared\n",
    "    x = np.array([_dss['SO4_Model']]).reshape((-1, 1))\n",
    "    model = LinearRegression().fit (x, _dss['N100_Model'])\n",
    "    r_sq = model.score(x, _dss['N100_Model'])\n",
    "    ax.text(0.3, 1.08, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "    #ax.text(0.3, 0.15, f\"R$^2$-value:{r_sq}0.3f\"  ,fontsize=8)\n",
    "    \n",
    "fig.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "fig.supylabel('N$_{100}$ (cm$^{-3}$)')\n",
    "fig.suptitle('Model SO4 vs N100')\n",
    "    \n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc07f0-acfc-4a74-96fc-3fba63b44a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "#ax.set_ylim ([0,750])\n",
    "#ax.set_xlim ([0,1.2])\n",
    "\n",
    "\n",
    "\n",
    "for seas, ax, col in zip(['DJF','MAM','JJA','SON'], axs.flatten(),['blue','green','orange','red']):\n",
    "    #print(seas)\n",
    "    _dss = masked.where(masked['season']==seas)\n",
    "    _dss = _dss.to_dataframe().dropna()\n",
    "    ax.scatter(x=_dss['SO4_Model'], y=_dss['N50_Model'],c= col, alpha = 0.2)\n",
    "    z = np.polyfit(_dss['SO4_Model'], _dss['N50_Model'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x= np.logspace(-2.2, np.log10(_dss['SO4_Model'].max()))\n",
    "    ax.plot( x, p(x), c = col, )\n",
    "    #print(p)\n",
    "    #ax.set_ylim ([0,300])\n",
    "    #ax.set_xlim ([0,1])\n",
    "    ax.set_yscale ('log')\n",
    "    ax.set_xscale ('log')\n",
    "    ax.set_title(seas)\n",
    "    \n",
    "    #Calculating R-Squared\n",
    "    x = np.array([_dss['SO4_Model']]).reshape((-1, 1))\n",
    "    model = LinearRegression().fit (x, _dss['N50_Model'])\n",
    "    r_sq = model.score(x, _dss['N50_Model'])\n",
    "    ax.text(0.2, 2.18, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "    #ax.text(0.3, 0.15, f\"R$^2$-value:{r_sq}0.3f\"  ,fontsize=8)\n",
    "    \n",
    "fig.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "fig.supylabel('N$_{50}$ (cm$^{-3}$)')\n",
    "fig.suptitle('Model SO4 vs N50')\n",
    "    \n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ce0b0-5196-4063-af97-c2efa9790c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "#ax.set_ylim ([0,750])\n",
    "#ax.set_xlim ([0,1.2])\n",
    "\n",
    "\n",
    "\n",
    "for seas, ax, col in zip(['DJF','MAM','JJA','SON'], axs.flatten(),['blue','green','orange','red']):\n",
    "    #print(seas)\n",
    "    _dss = masked.where(masked['season']==seas)\n",
    "    _dss = _dss.to_dataframe().dropna()\n",
    "    ax.scatter(x=_dss['SO4'], y=_dss['N50'],c= col, alpha = 0.2)\n",
    "    z = np.polyfit(_dss['SO4'], _dss['N50'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x= np.logspace(-0.7, np.log10(_dss['SO4'].max()))\n",
    "    ax.plot( x, p(x), c = col, )\n",
    "    #print(p)\n",
    "    #ax.set_ylim ([0,300])\n",
    "    #ax.set_xlim ([0,1])\n",
    "    ax.set_yscale ('log')\n",
    "    ax.set_xscale ('log')\n",
    "    ax.set_title(seas)\n",
    "    \n",
    "    #Calculating R-Squared\n",
    "    x = np.array([_dss['SO4']]).reshape((-1, 1))\n",
    "    model = LinearRegression().fit (x, _dss['N50'])\n",
    "    r_sq = model.score(x, _dss['N50'])\n",
    "    ax.text(1.2, 2.30, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "    #ax.text(0.3, 0.15, f\"R$^2$-value:{r_sq}0.3f\"  ,fontsize=8)\n",
    "    \n",
    "fig.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "fig.supylabel('N$_{50}$ (cm$^{-3}$)')\n",
    "fig.suptitle('Obs SO4 vs N50')\n",
    "    \n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5a074-085f-4717-9e8f-2a61e367cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsmf_S2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2c1b9-ca39-48bc-8936-dffed442d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly = ALLDATA.resample(time = 'w').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0a6ad-1c62-4997-b03e-66a5f0e7ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, tight_layout= True, figsize = (10,10))\n",
    "\n",
    "ax1.scatter(x = weekly['SO4'], y = weekly['SO4_Model'],alpha = 0.15)\n",
    "_dss = weekly.to_dataframe().dropna()\n",
    "z = np.polyfit(_dss['SO4'], _dss['SO4_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-1, np.log10(_dss['SO4'].max()))\n",
    "ax1.plot( x, p(x), c = 'blue', )\n",
    "ax1.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax1.text(1.5, 0.00095, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax1.set_xlim(0.08,5)\n",
    "ax1.set_title ('SO4')\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "\n",
    "ax2.scatter(x = weekly['N50'], y = weekly['N50_Model'],alpha = 0.15)\n",
    "z = np.polyfit(_dss['N50'], _dss['N50_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['N50'].min()), np.log10(_dss['N50'].max()))\n",
    "ax2.plot( x, p(x), c = 'blue', )\n",
    "ax2.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax2.text(200.0, 1.9, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_title ('N$_{50}$')\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "\n",
    "ax3.scatter(x = weekly['N100'], y = weekly['N100_Model'],alpha = 0.15)\n",
    "z = np.polyfit(_dss['N100'], _dss['N100_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['N100'].min()), np.log10(_dss['N100'].max()))\n",
    "ax3.plot( x, p(x), c = 'blue', )\n",
    "ax3.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax3.text(70.0, 0.6, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax3.set_title ('N$_{100}$')\n",
    "ax3.set_yscale ('log')\n",
    "ax3.set_xscale ('log')\n",
    "\n",
    "ax4.scatter(x = weekly['SS'], y = weekly['SS_Model'],alpha = 0.15)\n",
    "z = np.polyfit(_dss['SS'], _dss['SS_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-2, np.log10(_dss['SS'].max()))\n",
    "ax4.plot( x, p(x), c = 'blue', )\n",
    "ax4.plot( x, x, c = 'black', )\n",
    "#print(p)\n",
    "ax4.text(0.5, 0.00015, f\"Linear Regression = {p}\"  ,fontsize=8)\n",
    "\n",
    "ax4.set_title ('Sea Salt')\n",
    "ax4.set_yscale ('log')\n",
    "ax4.set_xscale ('log')\n",
    "\n",
    "f.supxlabel('Observations')\n",
    "f.supylabel('NorESM')\n",
    "#f.suptitle('NorESM data against Observation data')\n",
    "f.text(0, -0.05,\n",
    "         'Figure 5: NorESM data vs observation data at Zeppelin for respective variable concentrations. Black lines represent the 1:1 line, blue line represents the linear regression analysis.')\n",
    "\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3002884-2209-4836-9fcf-c455ec06258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly['season'] = weekly['time.season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba075d0c-20a4-423b-8cc1-724a7abbef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "#ax.set_ylim ([0,750])\n",
    "#ax.set_xlim ([0,1.2])\n",
    "\n",
    "\n",
    "\n",
    "for seas, ax, col in zip(['DJF','MAM','JJA','SON'], axs.flatten(),['blue','green','orange','red']):\n",
    "    #print(seas)\n",
    "    _dss = weekly.where(weekly['season']==seas)\n",
    "    _dss = _dss.to_dataframe().dropna()\n",
    "    ax.scatter(x=_dss['SO4'], y=_dss['N50'],c= col, alpha = 0.2)\n",
    "    z = np.polyfit(_dss['SO4'], _dss['N50'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x= np.logspace(-1.8, np.log10(_dss['SO4'].max()))\n",
    "    ax.plot( x, p(x), c = col, )\n",
    "    #print(p)\n",
    "    #ax.set_ylim ([0,300])\n",
    "    #ax.set_xlim ([0,1])\n",
    "    ax.set_yscale ('log')\n",
    "    ax.set_xscale ('log')\n",
    "    ax.set_title(seas)\n",
    "    \n",
    "    #Calculating R-Squared\n",
    "    x = np.array([_dss['SO4']]).reshape((-1, 1))\n",
    "    model = LinearRegression().fit (x, _dss['N50'])\n",
    "    r_sq = model.score(x, _dss['N50'])\n",
    "    ax.text(0.6, 19, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "    #ax.text(0.3, 0.15, f\"R$^2$-value:{r_sq}0.3f\"  ,fontsize=8)\n",
    "    \n",
    "fig.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "fig.supylabel('N$_{50}$ (cm$^{-3}$)')\n",
    "fig.suptitle('Obs SO4 vs N50')\n",
    "    \n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204d9b5-4194-4e31-bb1c-eed38852a41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1,2,tight_layout=True, sharey=True, sharex=True, figsize = (10,5))\n",
    "\n",
    "\n",
    "_dss = weekly[['SO4_Model','N50_Model']].dropna('time')\n",
    "ax1.scatter(x=_dss['SO4_Model'], y=_dss['N50_Model'],c='orange',alpha = 0.2)\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4_Model'], _dss['N50_Model'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(np.log10(_dss['SO4_Model'].min()), np.log10(_dss['SO4_Model'].max()))\n",
    "#print(p)\n",
    "ax1.plot( x, p(x), c = 'black', )\n",
    "ax1.text(0.083, 0.12, 'Linear regression : y = 293.8 x + 34.36' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4_Model']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50_Model'])\n",
    "r_sq = model.score(x, _dss['N50_Model'])\n",
    "#print(f\"coefficient of determination: {r_sq}\")\n",
    "ax1.text(0.9, 0.18, f'R$^2$ value : {r_sq:0.3f}' ,fontsize=8)\n",
    "\n",
    "ax1.set_ylim(0.1,10000)\n",
    "ax1.set_xlim(0.002,5)\n",
    "ax1.set_yscale ('log')\n",
    "ax1.set_xscale ('log')\n",
    "#ax1.set_xlabel('SO4 ug/m$^3$')\n",
    "#ax1.set_ylabel('N50')\n",
    "ax1.set_title(f'Model')\n",
    "\n",
    "_dss = weekly[['SO4','N50']].dropna('time')\n",
    "ax2.scatter(x=_dss['SO4'], y=_dss['N50'], alpha = 0.2 )\n",
    "\n",
    "#Linear regression\n",
    "z = np.polyfit(_dss['SO4'], _dss['N50'], 1)\n",
    "p = np.poly1d(z)\n",
    "x= np.logspace(-1.2, np.log10(_dss['SO4'].max()))\n",
    "#print(p)\n",
    "ax2.plot( x, p(x), c = 'black', )\n",
    "#ax2.text(0.09, 0.12, 'Linear regression : y = 122.5x + 74.98' ,fontsize=8)\n",
    "\n",
    "#Calculating R-Squared\n",
    "x = np.array([_dss['SO4']]).reshape((-1, 1))\n",
    "model = LinearRegression().fit (x, _dss['N50'])\n",
    "r_sq = model.score(x, _dss['N50'])\n",
    "#print(r_sq)\n",
    "ax2.text(1.05, 0.18, f\"R$^2$-value:{r_sq:.3f}\"  ,fontsize=8)\n",
    "\n",
    "ax2.set_ylim(0.1,10000)\n",
    "ax2.set_xlim(0.002,5)\n",
    "ax2.set_yscale ('log')\n",
    "ax2.set_xscale ('log')\n",
    "#plt.xlabel('SO4 ug/m$^3$')\n",
    "#plt.ylabel('N50 ')\n",
    "ax2.set_title(f'Observation')\n",
    "#f.suptitle('Influence of SO4 on N$_{50}$ at Zeppelin', fontsize=16)\n",
    "f.supxlabel('SO$_4$ (ug/m$^3$)')\n",
    "f.supylabel('N$_{50}$ (cm$^{-3}$)')\n",
    "\n",
    "f.text(0, -0.05,\n",
    "         'Figure 1: NorESM (yellow) vs obesrvation (blue) SO4 vs N$_{50}$ at Zeppelin Station in Ny-Ålesund. Black lines represent linear regressions plotted in log space.')\n",
    "\n",
    "sns.despine(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
